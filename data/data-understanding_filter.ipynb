{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gene_expression_data\n",
    "gene_expression_data = pd.read_csv('dataset/gene_expression_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_data = gene_expression_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_data\n",
    "\n",
    "# applu log2 transformation to gene_expression_data\n",
    "gene_expression_data = np.log2(gene_expression_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probeset_names = [\"234764_x_at\", \"211835_at\", \"1561937_x_at\", \"202716_at\",\n",
    "                  \"235305_s_at\", \"210538_s_at\", \"237461_at\", \"41660_at\", \"217892_s_at\", \n",
    "                  \"225822_at\", \"57532_at\", \"213489_at\", \"222641_s_at\", \"205159_at\",\n",
    "                  \"209012_at\", \"220522_at\", \"223709_s_at\", \"36129_at\",\n",
    "                  \"201848_s_at\", \"212704_at\", \"213622_at\", \"232531_at\", \n",
    "                  \"205666_at\", \"210789_x_at\", \"217809_at\", \"225291_at\", \n",
    "                  \"226488_at\", \"231131_at\", \"238662_at\", \"226098_at\", \"202387_at\",\n",
    "                  \"228217_s_at\", \"225553_at\", \"223995_at\", \"202613_at\", \"203200_s_at\"]\n",
    "# Ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM7500908_S001.Cel.gz</th>\n",
       "      <td>1.573956</td>\n",
       "      <td>1.358708</td>\n",
       "      <td>1.467337</td>\n",
       "      <td>1.682516</td>\n",
       "      <td>0.901045</td>\n",
       "      <td>1.566870</td>\n",
       "      <td>1.378121</td>\n",
       "      <td>1.314857</td>\n",
       "      <td>1.367516</td>\n",
       "      <td>1.203722</td>\n",
       "      <td>...</td>\n",
       "      <td>1.827632</td>\n",
       "      <td>1.781068</td>\n",
       "      <td>1.884390</td>\n",
       "      <td>1.911549</td>\n",
       "      <td>1.237442</td>\n",
       "      <td>1.163814</td>\n",
       "      <td>1.008850</td>\n",
       "      <td>0.863384</td>\n",
       "      <td>0.979565</td>\n",
       "      <td>1.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500909_S002.Cel.gz</th>\n",
       "      <td>1.501270</td>\n",
       "      <td>1.266687</td>\n",
       "      <td>1.441489</td>\n",
       "      <td>1.697444</td>\n",
       "      <td>0.898466</td>\n",
       "      <td>1.512690</td>\n",
       "      <td>1.404902</td>\n",
       "      <td>1.308036</td>\n",
       "      <td>1.186132</td>\n",
       "      <td>1.184976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.745982</td>\n",
       "      <td>1.695292</td>\n",
       "      <td>1.853015</td>\n",
       "      <td>1.860822</td>\n",
       "      <td>1.225456</td>\n",
       "      <td>1.131216</td>\n",
       "      <td>1.033660</td>\n",
       "      <td>0.827768</td>\n",
       "      <td>0.946664</td>\n",
       "      <td>0.991057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500910_S003.Cel.gz</th>\n",
       "      <td>1.572295</td>\n",
       "      <td>1.403879</td>\n",
       "      <td>1.475055</td>\n",
       "      <td>1.678755</td>\n",
       "      <td>0.943835</td>\n",
       "      <td>1.602569</td>\n",
       "      <td>1.397244</td>\n",
       "      <td>1.276248</td>\n",
       "      <td>1.386097</td>\n",
       "      <td>1.209603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855169</td>\n",
       "      <td>1.803324</td>\n",
       "      <td>1.910143</td>\n",
       "      <td>1.919126</td>\n",
       "      <td>1.194332</td>\n",
       "      <td>1.073024</td>\n",
       "      <td>0.979608</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.942262</td>\n",
       "      <td>0.930134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500911_S004.Cel.gz</th>\n",
       "      <td>1.568408</td>\n",
       "      <td>1.424381</td>\n",
       "      <td>1.467160</td>\n",
       "      <td>1.683042</td>\n",
       "      <td>0.960602</td>\n",
       "      <td>1.587572</td>\n",
       "      <td>1.396700</td>\n",
       "      <td>1.308648</td>\n",
       "      <td>1.189292</td>\n",
       "      <td>1.244711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.851257</td>\n",
       "      <td>1.815394</td>\n",
       "      <td>1.915093</td>\n",
       "      <td>1.919182</td>\n",
       "      <td>1.234088</td>\n",
       "      <td>1.132173</td>\n",
       "      <td>1.011347</td>\n",
       "      <td>0.849705</td>\n",
       "      <td>0.957190</td>\n",
       "      <td>1.026416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500912_S005.Cel.gz</th>\n",
       "      <td>1.539766</td>\n",
       "      <td>1.345685</td>\n",
       "      <td>1.510031</td>\n",
       "      <td>1.678672</td>\n",
       "      <td>0.920679</td>\n",
       "      <td>1.506824</td>\n",
       "      <td>1.407893</td>\n",
       "      <td>1.316358</td>\n",
       "      <td>1.106102</td>\n",
       "      <td>1.178847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.844406</td>\n",
       "      <td>1.804634</td>\n",
       "      <td>1.923897</td>\n",
       "      <td>1.923579</td>\n",
       "      <td>1.277163</td>\n",
       "      <td>1.160845</td>\n",
       "      <td>1.025072</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.958940</td>\n",
       "      <td>1.061314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501261_P035.Cel.gz</th>\n",
       "      <td>1.556027</td>\n",
       "      <td>1.442616</td>\n",
       "      <td>1.435475</td>\n",
       "      <td>1.611143</td>\n",
       "      <td>0.875487</td>\n",
       "      <td>1.620159</td>\n",
       "      <td>1.445213</td>\n",
       "      <td>1.185458</td>\n",
       "      <td>1.400633</td>\n",
       "      <td>1.219893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.890692</td>\n",
       "      <td>1.857291</td>\n",
       "      <td>1.922188</td>\n",
       "      <td>1.926001</td>\n",
       "      <td>1.193121</td>\n",
       "      <td>1.178108</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>0.875586</td>\n",
       "      <td>0.939403</td>\n",
       "      <td>0.992444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501262_P036.Cel.gz</th>\n",
       "      <td>1.571354</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>1.439426</td>\n",
       "      <td>1.588694</td>\n",
       "      <td>0.861261</td>\n",
       "      <td>1.670083</td>\n",
       "      <td>1.386461</td>\n",
       "      <td>1.261529</td>\n",
       "      <td>1.484148</td>\n",
       "      <td>1.144650</td>\n",
       "      <td>...</td>\n",
       "      <td>1.845503</td>\n",
       "      <td>1.803663</td>\n",
       "      <td>1.897703</td>\n",
       "      <td>1.896829</td>\n",
       "      <td>1.217497</td>\n",
       "      <td>1.111779</td>\n",
       "      <td>1.054508</td>\n",
       "      <td>0.896315</td>\n",
       "      <td>0.941541</td>\n",
       "      <td>0.941782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501263_P037.Cel.gz</th>\n",
       "      <td>1.577868</td>\n",
       "      <td>1.508984</td>\n",
       "      <td>1.432502</td>\n",
       "      <td>1.608838</td>\n",
       "      <td>0.896874</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>1.412795</td>\n",
       "      <td>1.206315</td>\n",
       "      <td>1.690520</td>\n",
       "      <td>1.231876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.860288</td>\n",
       "      <td>1.820226</td>\n",
       "      <td>1.897037</td>\n",
       "      <td>1.903291</td>\n",
       "      <td>1.217164</td>\n",
       "      <td>1.229332</td>\n",
       "      <td>1.003575</td>\n",
       "      <td>0.920958</td>\n",
       "      <td>0.975177</td>\n",
       "      <td>0.956990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501264_P038.Cel.gz</th>\n",
       "      <td>1.529582</td>\n",
       "      <td>1.470926</td>\n",
       "      <td>1.372001</td>\n",
       "      <td>1.619276</td>\n",
       "      <td>0.909069</td>\n",
       "      <td>1.606878</td>\n",
       "      <td>1.332085</td>\n",
       "      <td>1.201757</td>\n",
       "      <td>1.591939</td>\n",
       "      <td>1.281437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.864509</td>\n",
       "      <td>1.817612</td>\n",
       "      <td>1.901734</td>\n",
       "      <td>1.903339</td>\n",
       "      <td>1.230153</td>\n",
       "      <td>1.133131</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>0.855264</td>\n",
       "      <td>0.979496</td>\n",
       "      <td>0.945866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501265_P039.Cel.gz</th>\n",
       "      <td>1.629342</td>\n",
       "      <td>1.464535</td>\n",
       "      <td>1.341281</td>\n",
       "      <td>1.599727</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>1.644338</td>\n",
       "      <td>1.394578</td>\n",
       "      <td>1.162397</td>\n",
       "      <td>1.217440</td>\n",
       "      <td>1.094684</td>\n",
       "      <td>...</td>\n",
       "      <td>1.848006</td>\n",
       "      <td>1.819512</td>\n",
       "      <td>1.903897</td>\n",
       "      <td>1.908706</td>\n",
       "      <td>1.152546</td>\n",
       "      <td>1.115685</td>\n",
       "      <td>0.994597</td>\n",
       "      <td>0.874388</td>\n",
       "      <td>0.932551</td>\n",
       "      <td>0.926696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows Ã— 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        1007_s_at   1053_at    117_at    121_at  1255_g_at  \\\n",
       "GSM7500908_S001.Cel.gz   1.573956  1.358708  1.467337  1.682516   0.901045   \n",
       "GSM7500909_S002.Cel.gz   1.501270  1.266687  1.441489  1.697444   0.898466   \n",
       "GSM7500910_S003.Cel.gz   1.572295  1.403879  1.475055  1.678755   0.943835   \n",
       "GSM7500911_S004.Cel.gz   1.568408  1.424381  1.467160  1.683042   0.960602   \n",
       "GSM7500912_S005.Cel.gz   1.539766  1.345685  1.510031  1.678672   0.920679   \n",
       "...                           ...       ...       ...       ...        ...   \n",
       "GSM7501261_P035.Cel.gz   1.556027  1.442616  1.435475  1.611143   0.875487   \n",
       "GSM7501262_P036.Cel.gz   1.571354  1.478423  1.439426  1.588694   0.861261   \n",
       "GSM7501263_P037.Cel.gz   1.577868  1.508984  1.432502  1.608838   0.896874   \n",
       "GSM7501264_P038.Cel.gz   1.529582  1.470926  1.372001  1.619276   0.909069   \n",
       "GSM7501265_P039.Cel.gz   1.629342  1.464535  1.341281  1.599727   0.839590   \n",
       "\n",
       "                         1294_at   1316_at   1320_at  1405_i_at   1431_at  \\\n",
       "GSM7500908_S001.Cel.gz  1.566870  1.378121  1.314857   1.367516  1.203722   \n",
       "GSM7500909_S002.Cel.gz  1.512690  1.404902  1.308036   1.186132  1.184976   \n",
       "GSM7500910_S003.Cel.gz  1.602569  1.397244  1.276248   1.386097  1.209603   \n",
       "GSM7500911_S004.Cel.gz  1.587572  1.396700  1.308648   1.189292  1.244711   \n",
       "GSM7500912_S005.Cel.gz  1.506824  1.407893  1.316358   1.106102  1.178847   \n",
       "...                          ...       ...       ...        ...       ...   \n",
       "GSM7501261_P035.Cel.gz  1.620159  1.445213  1.185458   1.400633  1.219893   \n",
       "GSM7501262_P036.Cel.gz  1.670083  1.386461  1.261529   1.484148  1.144650   \n",
       "GSM7501263_P037.Cel.gz  1.671715  1.412795  1.206315   1.690520  1.231876   \n",
       "GSM7501264_P038.Cel.gz  1.606878  1.332085  1.201757   1.591939  1.281437   \n",
       "GSM7501265_P039.Cel.gz  1.644338  1.394578  1.162397   1.217440  1.094684   \n",
       "\n",
       "                        ...  AFFX-r2-Ec-bioD-3_at  AFFX-r2-Ec-bioD-5_at  \\\n",
       "GSM7500908_S001.Cel.gz  ...              1.827632              1.781068   \n",
       "GSM7500909_S002.Cel.gz  ...              1.745982              1.695292   \n",
       "GSM7500910_S003.Cel.gz  ...              1.855169              1.803324   \n",
       "GSM7500911_S004.Cel.gz  ...              1.851257              1.815394   \n",
       "GSM7500912_S005.Cel.gz  ...              1.844406              1.804634   \n",
       "...                     ...                   ...                   ...   \n",
       "GSM7501261_P035.Cel.gz  ...              1.890692              1.857291   \n",
       "GSM7501262_P036.Cel.gz  ...              1.845503              1.803663   \n",
       "GSM7501263_P037.Cel.gz  ...              1.860288              1.820226   \n",
       "GSM7501264_P038.Cel.gz  ...              1.864509              1.817612   \n",
       "GSM7501265_P039.Cel.gz  ...              1.848006              1.819512   \n",
       "\n",
       "                        AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "GSM7500908_S001.Cel.gz             1.884390             1.911549   \n",
       "GSM7500909_S002.Cel.gz             1.853015             1.860822   \n",
       "GSM7500910_S003.Cel.gz             1.910143             1.919126   \n",
       "GSM7500911_S004.Cel.gz             1.915093             1.919182   \n",
       "GSM7500912_S005.Cel.gz             1.923897             1.923579   \n",
       "...                                     ...                  ...   \n",
       "GSM7501261_P035.Cel.gz             1.922188             1.926001   \n",
       "GSM7501262_P036.Cel.gz             1.897703             1.896829   \n",
       "GSM7501263_P037.Cel.gz             1.897037             1.903291   \n",
       "GSM7501264_P038.Cel.gz             1.901734             1.903339   \n",
       "GSM7501265_P039.Cel.gz             1.903897             1.908706   \n",
       "\n",
       "                        AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  \\\n",
       "GSM7500908_S001.Cel.gz        1.237442        1.163814        1.008850   \n",
       "GSM7500909_S002.Cel.gz        1.225456        1.131216        1.033660   \n",
       "GSM7500910_S003.Cel.gz        1.194332        1.073024        0.979608   \n",
       "GSM7500911_S004.Cel.gz        1.234088        1.132173        1.011347   \n",
       "GSM7500912_S005.Cel.gz        1.277163        1.160845        1.025072   \n",
       "...                                ...             ...             ...   \n",
       "GSM7501261_P035.Cel.gz        1.193121        1.178108        0.956692   \n",
       "GSM7501262_P036.Cel.gz        1.217497        1.111779        1.054508   \n",
       "GSM7501263_P037.Cel.gz        1.217164        1.229332        1.003575   \n",
       "GSM7501264_P038.Cel.gz        1.230153        1.133131        0.989612   \n",
       "GSM7501265_P039.Cel.gz        1.152546        1.115685        0.994597   \n",
       "\n",
       "                        AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "GSM7500908_S001.Cel.gz         0.863384         0.979565         1.003787  \n",
       "GSM7500909_S002.Cel.gz         0.827768         0.946664         0.991057  \n",
       "GSM7500910_S003.Cel.gz         0.860452         0.942262         0.930134  \n",
       "GSM7500911_S004.Cel.gz         0.849705         0.957190         1.026416  \n",
       "GSM7500912_S005.Cel.gz         0.833648         0.958940         1.061314  \n",
       "...                                 ...              ...              ...  \n",
       "GSM7501261_P035.Cel.gz         0.875586         0.939403         0.992444  \n",
       "GSM7501262_P036.Cel.gz         0.896315         0.941541         0.941782  \n",
       "GSM7501263_P037.Cel.gz         0.920958         0.975177         0.956990  \n",
       "GSM7501264_P038.Cel.gz         0.855264         0.979496         0.945866  \n",
       "GSM7501265_P039.Cel.gz         0.874388         0.932551         0.926696  \n",
       "\n",
       "[358 rows x 54675 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probset_expression_data = gene_expression_data[probeset_names]\n",
    "\n",
    "probset_expression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a heatmap of the probset_expression_data\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(probset_expression_data, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_regulated = [\"234764_x_at\", \"211835_at\", \"1561937_x_at\", \"202716_at\", \n",
    "                  \"235305_s_at\", \"210538_s_at\", \"237461_at\", \"41660_at\", \"217892_s_at\",\n",
    "                  \"225822_at\", \"57532_at\", \"213489_at\", \"222641_s_at\", \"205159_at\", \"209012_at\",\n",
    "                  \"220522_at\", \"223709_s_at\", \"36129_at\", \"201848_s_at\", \"212704_at\", \"213622_at\",\n",
    "                  \"232531_at\", \"205666_at\", \"210789_x_at\"]\n",
    "\n",
    "# Calculate the average expression for Up-Regulated Probesets\n",
    "up_regulated = [\"217809_at\", \"225291_at\", \"226488_at\", \"231131_at\",\n",
    "                \"238662_at\", \"226098_at\", \"202387_at\", \"228217_s_at\",\n",
    "                \"225553_at\", \"223995_at\", \"202613_at\", \"203200_s_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSM7501168_S261.Cel.gz    0.215409\n",
       "GSM7501264_P038.Cel.gz    0.191269\n",
       "GSM7501260_P034.Cel.gz    0.169567\n",
       "GSM7501265_P039.Cel.gz    0.159906\n",
       "GSM7501251_P025.Cel.gz    0.154354\n",
       "                            ...   \n",
       "GSM7500929_S022.Cel.gz   -0.135820\n",
       "GSM7500981_S074.Cel.gz   -0.136464\n",
       "GSM7500915_S008.Cel.gz   -0.141767\n",
       "GSM7500994_S087.Cel.gz   -0.144432\n",
       "GSM7500947_S040.Cel.gz   -0.150606\n",
       "Length: 358, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probset_down_regulated = probset_expression_data[down_regulated]\n",
    "\n",
    "probset_up_regulated = probset_expression_data[up_regulated]\n",
    "\n",
    "# get difference between up and down regulated\n",
    "diff = probset_up_regulated.mean(axis=1) - probset_down_regulated.mean(axis=1)\n",
    "\n",
    "\n",
    "diff = diff.sort_values(ascending=False)\n",
    "\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/272575413.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if diff[i] > 0.7:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Low risk MGUS',\n",
       " 1: 'Low risk MGUS',\n",
       " 2: 'Low risk MGUS',\n",
       " 3: 'Low risk MGUS',\n",
       " 4: 'Low risk MGUS',\n",
       " 5: 'Low risk MGUS',\n",
       " 6: 'Low risk MGUS',\n",
       " 7: 'Low risk MGUS',\n",
       " 8: 'Low risk MGUS',\n",
       " 9: 'Low risk MGUS',\n",
       " 10: 'Low risk MGUS',\n",
       " 11: 'Low risk MGUS',\n",
       " 12: 'Low risk MGUS',\n",
       " 13: 'Low risk MGUS',\n",
       " 14: 'Low risk MGUS',\n",
       " 15: 'Low risk MGUS',\n",
       " 16: 'Low risk MGUS',\n",
       " 17: 'Low risk MGUS',\n",
       " 18: 'Low risk MGUS',\n",
       " 19: 'Low risk MGUS',\n",
       " 20: 'Low risk MGUS',\n",
       " 21: 'Low risk MGUS',\n",
       " 22: 'Low risk MGUS',\n",
       " 23: 'Low risk MGUS',\n",
       " 24: 'Low risk MGUS',\n",
       " 25: 'Low risk MGUS',\n",
       " 26: 'Low risk MGUS',\n",
       " 27: 'Low risk MGUS',\n",
       " 28: 'Low risk MGUS',\n",
       " 29: 'Low risk MGUS',\n",
       " 30: 'Low risk MGUS',\n",
       " 31: 'Low risk MGUS',\n",
       " 32: 'Low risk MGUS',\n",
       " 33: 'Low risk MGUS',\n",
       " 34: 'Low risk MGUS',\n",
       " 35: 'Low risk MGUS',\n",
       " 36: 'Low risk MGUS',\n",
       " 37: 'Low risk MGUS',\n",
       " 38: 'Low risk MGUS',\n",
       " 39: 'Low risk MGUS',\n",
       " 40: 'Low risk MGUS',\n",
       " 41: 'Low risk MGUS',\n",
       " 42: 'Low risk MGUS',\n",
       " 43: 'Low risk MGUS',\n",
       " 44: 'Low risk MGUS',\n",
       " 45: 'Low risk MGUS',\n",
       " 46: 'Low risk MGUS',\n",
       " 47: 'Low risk MGUS',\n",
       " 48: 'Low risk MGUS',\n",
       " 49: 'Low risk MGUS',\n",
       " 50: 'Low risk MGUS',\n",
       " 51: 'Low risk MGUS',\n",
       " 52: 'Low risk MGUS',\n",
       " 53: 'Low risk MGUS',\n",
       " 54: 'Low risk MGUS',\n",
       " 55: 'Low risk MGUS',\n",
       " 56: 'Low risk MGUS',\n",
       " 57: 'Low risk MGUS',\n",
       " 58: 'Low risk MGUS',\n",
       " 59: 'Low risk MGUS',\n",
       " 60: 'Low risk MGUS',\n",
       " 61: 'Low risk MGUS',\n",
       " 62: 'Low risk MGUS',\n",
       " 63: 'Low risk MGUS',\n",
       " 64: 'Low risk MGUS',\n",
       " 65: 'Low risk MGUS',\n",
       " 66: 'Low risk MGUS',\n",
       " 67: 'Low risk MGUS',\n",
       " 68: 'Low risk MGUS',\n",
       " 69: 'Low risk MGUS',\n",
       " 70: 'Low risk MGUS',\n",
       " 71: 'Low risk MGUS',\n",
       " 72: 'Low risk MGUS',\n",
       " 73: 'Low risk MGUS',\n",
       " 74: 'Low risk MGUS',\n",
       " 75: 'Low risk MGUS',\n",
       " 76: 'Low risk MGUS',\n",
       " 77: 'Low risk MGUS',\n",
       " 78: 'Low risk MGUS',\n",
       " 79: 'Low risk MGUS',\n",
       " 80: 'Low risk MGUS',\n",
       " 81: 'Low risk MGUS',\n",
       " 82: 'Low risk MGUS',\n",
       " 83: 'Low risk MGUS',\n",
       " 84: 'Low risk MGUS',\n",
       " 85: 'Low risk MGUS',\n",
       " 86: 'Low risk MGUS',\n",
       " 87: 'Low risk MGUS',\n",
       " 88: 'Low risk MGUS',\n",
       " 89: 'Low risk MGUS',\n",
       " 90: 'Low risk MGUS',\n",
       " 91: 'Low risk MGUS',\n",
       " 92: 'Low risk MGUS',\n",
       " 93: 'Low risk MGUS',\n",
       " 94: 'Low risk MGUS',\n",
       " 95: 'Low risk MGUS',\n",
       " 96: 'Low risk MGUS',\n",
       " 97: 'Low risk MGUS',\n",
       " 98: 'Low risk MGUS',\n",
       " 99: 'Low risk MGUS',\n",
       " 100: 'Low risk MGUS',\n",
       " 101: 'Low risk MGUS',\n",
       " 102: 'Low risk MGUS',\n",
       " 103: 'Low risk MGUS',\n",
       " 104: 'Low risk MGUS',\n",
       " 105: 'Low risk MGUS',\n",
       " 106: 'Low risk MGUS',\n",
       " 107: 'Low risk MGUS',\n",
       " 108: 'Low risk MGUS',\n",
       " 109: 'Low risk MGUS',\n",
       " 110: 'Low risk MGUS',\n",
       " 111: 'Low risk MGUS',\n",
       " 112: 'Low risk MGUS',\n",
       " 113: 'Low risk MGUS',\n",
       " 114: 'Low risk MGUS',\n",
       " 115: 'Low risk MGUS',\n",
       " 116: 'Low risk MGUS',\n",
       " 117: 'Low risk MGUS',\n",
       " 118: 'Low risk MGUS',\n",
       " 119: 'Low risk MGUS',\n",
       " 120: 'Low risk MGUS',\n",
       " 121: 'Low risk MGUS',\n",
       " 122: 'Low risk MGUS',\n",
       " 123: 'Low risk MGUS',\n",
       " 124: 'Low risk MGUS',\n",
       " 125: 'Low risk MGUS',\n",
       " 126: 'Low risk MGUS',\n",
       " 127: 'Low risk MGUS',\n",
       " 128: 'Low risk MGUS',\n",
       " 129: 'Low risk MGUS',\n",
       " 130: 'Low risk MGUS',\n",
       " 131: 'Low risk MGUS',\n",
       " 132: 'Low risk MGUS',\n",
       " 133: 'Low risk MGUS',\n",
       " 134: 'Low risk MGUS',\n",
       " 135: 'Low risk MGUS',\n",
       " 136: 'Low risk MGUS',\n",
       " 137: 'Low risk MGUS',\n",
       " 138: 'Low risk MGUS',\n",
       " 139: 'Low risk MGUS',\n",
       " 140: 'Low risk MGUS',\n",
       " 141: 'Low risk MGUS',\n",
       " 142: 'Low risk MGUS',\n",
       " 143: 'Low risk MGUS',\n",
       " 144: 'Low risk MGUS',\n",
       " 145: 'Low risk MGUS',\n",
       " 146: 'Low risk MGUS',\n",
       " 147: 'Low risk MGUS',\n",
       " 148: 'Low risk MGUS',\n",
       " 149: 'Low risk MGUS',\n",
       " 150: 'Low risk MGUS',\n",
       " 151: 'Low risk MGUS',\n",
       " 152: 'Low risk MGUS',\n",
       " 153: 'Low risk MGUS',\n",
       " 154: 'Low risk MGUS',\n",
       " 155: 'Low risk MGUS',\n",
       " 156: 'Low risk MGUS',\n",
       " 157: 'Low risk MGUS',\n",
       " 158: 'Low risk MGUS',\n",
       " 159: 'Low risk MGUS',\n",
       " 160: 'Low risk MGUS',\n",
       " 161: 'Low risk MGUS',\n",
       " 162: 'Low risk MGUS',\n",
       " 163: 'Low risk MGUS',\n",
       " 164: 'Low risk MGUS',\n",
       " 165: 'Low risk MGUS',\n",
       " 166: 'Low risk MGUS',\n",
       " 167: 'Low risk MGUS',\n",
       " 168: 'Low risk MGUS',\n",
       " 169: 'Low risk MGUS',\n",
       " 170: 'Low risk MGUS',\n",
       " 171: 'Low risk MGUS',\n",
       " 172: 'Low risk MGUS',\n",
       " 173: 'Low risk MGUS',\n",
       " 174: 'Low risk MGUS',\n",
       " 175: 'Low risk MGUS',\n",
       " 176: 'Low risk MGUS',\n",
       " 177: 'Low risk MGUS',\n",
       " 178: 'Low risk MGUS',\n",
       " 179: 'Low risk MGUS',\n",
       " 180: 'Low risk MGUS',\n",
       " 181: 'Low risk MGUS',\n",
       " 182: 'Low risk MGUS',\n",
       " 183: 'Low risk MGUS',\n",
       " 184: 'Low risk MGUS',\n",
       " 185: 'Low risk MGUS',\n",
       " 186: 'Low risk MGUS',\n",
       " 187: 'Low risk MGUS',\n",
       " 188: 'Low risk MGUS',\n",
       " 189: 'Low risk MGUS',\n",
       " 190: 'Low risk MGUS',\n",
       " 191: 'Low risk MGUS',\n",
       " 192: 'Low risk MGUS',\n",
       " 193: 'Low risk MGUS',\n",
       " 194: 'Low risk MGUS',\n",
       " 195: 'Low risk MGUS',\n",
       " 196: 'Low risk MGUS',\n",
       " 197: 'Low risk MGUS',\n",
       " 198: 'Low risk MGUS',\n",
       " 199: 'Low risk MGUS',\n",
       " 200: 'Low risk MGUS',\n",
       " 201: 'Low risk MGUS',\n",
       " 202: 'Low risk MGUS',\n",
       " 203: 'Low risk MGUS',\n",
       " 204: 'Low risk MGUS',\n",
       " 205: 'Low risk MGUS',\n",
       " 206: 'Low risk MGUS',\n",
       " 207: 'Low risk MGUS',\n",
       " 208: 'Low risk MGUS',\n",
       " 209: 'Low risk MGUS',\n",
       " 210: 'Low risk MGUS',\n",
       " 211: 'Low risk MGUS',\n",
       " 212: 'Low risk MGUS',\n",
       " 213: 'Low risk MGUS',\n",
       " 214: 'Low risk MGUS',\n",
       " 215: 'Low risk MGUS',\n",
       " 216: 'Low risk MGUS',\n",
       " 217: 'Low risk MGUS',\n",
       " 218: 'Low risk MGUS',\n",
       " 219: 'Low risk MGUS',\n",
       " 220: 'Low risk MGUS',\n",
       " 221: 'Low risk MGUS',\n",
       " 222: 'Low risk MGUS',\n",
       " 223: 'Low risk MGUS',\n",
       " 224: 'Low risk MGUS',\n",
       " 225: 'Low risk MGUS',\n",
       " 226: 'Low risk MGUS',\n",
       " 227: 'Low risk MGUS',\n",
       " 228: 'Low risk MGUS',\n",
       " 229: 'Low risk MGUS',\n",
       " 230: 'Low risk MGUS',\n",
       " 231: 'Low risk MGUS',\n",
       " 232: 'Low risk MGUS',\n",
       " 233: 'Low risk MGUS',\n",
       " 234: 'Low risk MGUS',\n",
       " 235: 'Low risk MGUS',\n",
       " 236: 'Low risk MGUS',\n",
       " 237: 'Low risk MGUS',\n",
       " 238: 'Low risk MGUS',\n",
       " 239: 'Low risk MGUS',\n",
       " 240: 'Low risk MGUS',\n",
       " 241: 'Low risk MGUS',\n",
       " 242: 'Low risk MGUS',\n",
       " 243: 'Low risk MGUS',\n",
       " 244: 'Low risk MGUS',\n",
       " 245: 'Low risk MGUS',\n",
       " 246: 'Low risk MGUS',\n",
       " 247: 'Low risk MGUS',\n",
       " 248: 'Low risk MGUS',\n",
       " 249: 'Low risk MGUS',\n",
       " 250: 'Low risk MGUS',\n",
       " 251: 'Low risk MGUS',\n",
       " 252: 'Low risk MGUS',\n",
       " 253: 'Low risk MGUS',\n",
       " 254: 'Low risk MGUS',\n",
       " 255: 'Low risk MGUS',\n",
       " 256: 'Low risk MGUS',\n",
       " 257: 'Low risk MGUS',\n",
       " 258: 'Low risk MGUS',\n",
       " 259: 'Low risk MGUS',\n",
       " 260: 'Low risk MGUS',\n",
       " 261: 'Low risk MGUS',\n",
       " 262: 'Low risk MGUS',\n",
       " 263: 'Low risk MGUS',\n",
       " 264: 'Low risk MGUS',\n",
       " 265: 'Low risk MGUS',\n",
       " 266: 'Low risk MGUS',\n",
       " 267: 'Low risk MGUS',\n",
       " 268: 'Low risk MGUS',\n",
       " 269: 'Low risk MGUS',\n",
       " 270: 'Low risk MGUS',\n",
       " 271: 'Low risk MGUS',\n",
       " 272: 'Low risk MGUS',\n",
       " 273: 'Low risk MGUS',\n",
       " 274: 'Low risk MGUS',\n",
       " 275: 'Low risk MGUS',\n",
       " 276: 'Low risk MGUS',\n",
       " 277: 'Low risk MGUS',\n",
       " 278: 'Low risk MGUS',\n",
       " 279: 'Low risk MGUS',\n",
       " 280: 'Low risk MGUS',\n",
       " 281: 'Low risk MGUS',\n",
       " 282: 'Low risk MGUS',\n",
       " 283: 'Low risk MGUS',\n",
       " 284: 'Low risk MGUS',\n",
       " 285: 'Low risk MGUS',\n",
       " 286: 'Low risk MGUS',\n",
       " 287: 'Low risk MGUS',\n",
       " 288: 'Low risk MGUS',\n",
       " 289: 'Low risk MGUS',\n",
       " 290: 'Low risk MGUS',\n",
       " 291: 'Low risk MGUS',\n",
       " 292: 'Low risk MGUS',\n",
       " 293: 'Low risk MGUS',\n",
       " 294: 'Low risk MGUS',\n",
       " 295: 'Low risk MGUS',\n",
       " 296: 'Low risk MGUS',\n",
       " 297: 'Low risk MGUS',\n",
       " 298: 'Low risk MGUS',\n",
       " 299: 'Low risk MGUS',\n",
       " 300: 'Low risk MGUS',\n",
       " 301: 'Low risk MGUS',\n",
       " 302: 'Low risk MGUS',\n",
       " 303: 'Low risk MGUS',\n",
       " 304: 'Low risk MGUS',\n",
       " 305: 'Low risk MGUS',\n",
       " 306: 'Low risk MGUS',\n",
       " 307: 'Low risk MGUS',\n",
       " 308: 'Low risk MGUS',\n",
       " 309: 'Low risk MGUS',\n",
       " 310: 'Low risk MGUS',\n",
       " 311: 'Low risk MGUS',\n",
       " 312: 'Low risk MGUS',\n",
       " 313: 'Low risk MGUS',\n",
       " 314: 'Low risk MGUS',\n",
       " 315: 'Low risk MGUS',\n",
       " 316: 'Low risk MGUS',\n",
       " 317: 'Low risk MGUS',\n",
       " 318: 'Low risk MGUS',\n",
       " 319: 'Low risk MGUS',\n",
       " 320: 'Low risk MGUS',\n",
       " 321: 'Low risk MGUS',\n",
       " 322: 'Low risk MGUS',\n",
       " 323: 'Low risk MGUS',\n",
       " 324: 'Low risk MGUS',\n",
       " 325: 'Low risk MGUS',\n",
       " 326: 'Low risk MGUS',\n",
       " 327: 'Low risk MGUS',\n",
       " 328: 'Low risk MGUS',\n",
       " 329: 'Low risk MGUS',\n",
       " 330: 'Low risk MGUS',\n",
       " 331: 'Low risk MGUS',\n",
       " 332: 'Low risk MGUS',\n",
       " 333: 'Low risk MGUS',\n",
       " 334: 'Low risk MGUS',\n",
       " 335: 'Low risk MGUS',\n",
       " 336: 'Low risk MGUS',\n",
       " 337: 'Low risk MGUS',\n",
       " 338: 'Low risk MGUS',\n",
       " 339: 'Low risk MGUS',\n",
       " 340: 'Low risk MGUS',\n",
       " 341: 'Low risk MGUS',\n",
       " 342: 'Low risk MGUS',\n",
       " 343: 'Low risk MGUS',\n",
       " 344: 'Low risk MGUS',\n",
       " 345: 'Low risk MGUS',\n",
       " 346: 'Low risk MGUS',\n",
       " 347: 'Low risk MGUS',\n",
       " 348: 'Low risk MGUS',\n",
       " 349: 'Low risk MGUS',\n",
       " 350: 'Low risk MGUS',\n",
       " 351: 'Low risk MGUS',\n",
       " 352: 'Low risk MGUS',\n",
       " 353: 'Low risk MGUS',\n",
       " 354: 'Low risk MGUS',\n",
       " 355: 'Low risk MGUS',\n",
       " 356: 'Low risk MGUS',\n",
       " 357: 'Low risk MGUS'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgus_patients_risk = {}\n",
    "for i in range(len(diff)):\n",
    "    if diff[i] > 0.7:\n",
    "        # append to patient i risk high\n",
    "        mgus_patients_risk[i] = \"High risk MGUS\"\n",
    "    else:\n",
    "        mgus_patients_risk[i] = \"Low risk MGUS\"\n",
    "        \n",
    "mgus_patients_risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels 0 or 1 if disease is stable or progressing \n",
    "def add_state(row):\n",
    "    if '_S' in str(row.name):  # Ensure it's a string for the 'in' operation\n",
    "        return 0\n",
    "    elif '_P' in str(row.name):\n",
    "        return 1\n",
    "\n",
    "gene_expression_data['state'] = gene_expression_data.apply(add_state, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "0    319\n",
       "1     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation, sort it, and select the top 150 feature names\n",
    "high_std_features = gene_expression_data.drop('state', axis=1).std().sort_values().tail(300).index\n",
    "selected_features = high_std_features.tolist() + ['state']\n",
    "selected_data = gene_expression_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSM7500908_S001.Cel.gz    0\n",
       "GSM7500909_S002.Cel.gz    0\n",
       "GSM7500910_S003.Cel.gz    0\n",
       "GSM7500911_S004.Cel.gz    0\n",
       "GSM7500912_S005.Cel.gz    0\n",
       "                         ..\n",
       "GSM7501261_P035.Cel.gz    1\n",
       "GSM7501262_P036.Cel.gz    1\n",
       "GSM7501263_P037.Cel.gz    1\n",
       "GSM7501264_P038.Cel.gz    1\n",
       "GSM7501265_P039.Cel.gz    1\n",
       "Name: state, Length: 358, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and Labels\n",
    "X = selected_data.drop('state', axis=1)  # Dropping the 'state' column to isolate features\n",
    "y = selected_data['state']  # Labels\n",
    "\n",
    "# Splitting the data into training and temporary sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Splitting the temporary set into validation and test sets (50% validation, 50% test)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86        48\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.44      0.43      0.43        54\n",
      "weighted avg       0.78      0.76      0.77        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initializing the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Training the classifier\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_pred_validation = clf.predict(X_validation)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=300)  # You can adjust n_estimators and other parameters as needed\n",
    "\n",
    "# Train the classifier on the balanced training data\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation_rf = rf_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        48\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.83        54\n",
      "   macro avg       0.44      0.47      0.45        54\n",
      "weighted avg       0.78      0.83      0.81        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87        48\n",
      "           1       0.12      0.17      0.14         6\n",
      "\n",
      "    accuracy                           0.78        54\n",
      "   macro avg       0.51      0.51      0.51        54\n",
      "weighted avg       0.81      0.78      0.79        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_clf = SVC(kernel='linear', class_weight='balanced', random_state=42)  # Consider adjusting the kernel and other parameters as needed\n",
    "\n",
    "# Train the classifier on the balanced training data\n",
    "svm_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation_svm = svm_clf.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutto delundente. What if non facessimo selection all'inizio?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gene_expression_data.drop('state', axis=1)  # Dropping the 'state' column to isolate features\n",
    "y = gene_expression_data['state']  # Labels\n",
    "\n",
    "# Splitting the data into training and temporary sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Splitting the temporary set into validation and test sets (50% validation, 50% test)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        48\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.87        54\n",
      "   macro avg       0.44      0.49      0.47        54\n",
      "weighted avg       0.79      0.87      0.83        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='linear', class_weight='balanced', random_state=42)  # Consider adjusting the kernel and other parameters as needed\n",
    "\n",
    "# Train the classifier on the balanced training data\n",
    "svm_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation_svm = svm_clf.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=300, min_samples_split=2)  # You can adjust n_estimators and other parameters as needed\n",
    "\n",
    "# Train the classifier on the balanced training data\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation_rf = rf_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        48\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.44      0.50      0.47        54\n",
      "weighted avg       0.79      0.89      0.84        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam,SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Scaling data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Computing class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Getting weights dictionary\n",
    "class_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/4156183785.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7400000095367432\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85        44\n",
      "           1       0.11      0.17      0.13         6\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.49      0.49      0.49        50\n",
      "weighted avg       0.79      0.74      0.76        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[36  8]\n",
      " [ 5  1]]\n",
      "ROC AUC Score: 0.571969696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/4156183785.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8600000143051147\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.43      0.50      0.46         6\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.68      0.70      0.69        50\n",
      "weighted avg       0.87      0.86      0.86        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  4]\n",
      " [ 3  3]]\n",
      "ROC AUC Score: 0.6439393939393939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/4156183785.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8600000143051147\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        45\n",
      "           1       0.25      0.20      0.22         5\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.58      0.57      0.57        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42  3]\n",
      " [ 4  1]]\n",
      "ROC AUC Score: 0.6311111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/4156183785.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7799999713897705\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87        45\n",
      "           1       0.20      0.40      0.27         5\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.56      0.61      0.57        50\n",
      "weighted avg       0.85      0.78      0.81        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37  8]\n",
      " [ 3  2]]\n",
      "ROC AUC Score: 0.7377777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/4156183785.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7799999713897705\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x31c439760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        45\n",
      "           1       0.12      0.20      0.15         5\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.51      0.52      0.51        50\n",
      "weighted avg       0.83      0.78      0.80        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38  7]\n",
      " [ 4  1]]\n",
      "ROC AUC Score: 0.7288888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    return model\n",
    "\n",
    "# Training and evaluation\n",
    "for train_index, test_index in skf.split(X_train_scaled, y_train):\n",
    "    # Splitting data\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(input_dim=X_train_fold.shape[1])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = SGD(lr=0.001, momentum=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, y_train_fold,\n",
    "                        validation_data=(X_val_fold, y_val_fold),\n",
    "                        epochs=100, batch_size=30, verbose=0, class_weight=class_weight_dict)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    print(f'Validation Accuracy: {scores[1]}')\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_val_fold, y_pred > 0.5))  # Threshold can be adjusted\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred > 0.5)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # ROC AUC Score\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_pred)\n",
    "    print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_val_fold, y_pred)\n",
    "    # Plot ROC curve\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_val_fold, y_pred)\n",
    "    # Plot Precision-Recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still nothing. Sigh.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-test filter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-values: [0.99711782 0.85741222 0.4012185  ... 0.97320467 0.18156975 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/2996896986.py:29: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  z_statistic = mean_difference / std_error_difference\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def two_sample_z_test_for_features(data_group1, data_group2):\n",
    "\n",
    "    num_features = data_group1.shape[1]\n",
    "    p_values = np.zeros(num_features)\n",
    "    for i in range(num_features):\n",
    "        feature_data_group1 = data_group1.iloc[:, i]\n",
    "        feature_data_group2 = data_group2.iloc[:, i]\n",
    "        mean_group1 = np.mean(feature_data_group1)\n",
    "        mean_group2 = np.mean(feature_data_group2)\n",
    "        \n",
    "        std_dev_group1 = np.std(feature_data_group1)\n",
    "        std_dev_group2 = np.std(feature_data_group2)\n",
    "        \n",
    "        sample_size_group1 = len(feature_data_group1)\n",
    "        sample_size_group2 = len(feature_data_group2)\n",
    "        \n",
    "        # Assuming null hypothesis: mean of group1 - mean of group2 = 0\n",
    "        mean_difference = mean_group1 - mean_group2\n",
    "        \n",
    "        # Calculate the standard error of the difference between means\n",
    "        std_error_difference = np.sqrt((std_dev_group1**2 / sample_size_group1) + \n",
    "                                        (std_dev_group2**2 / sample_size_group2))\n",
    "        \n",
    "        # Compute z-statistic\n",
    "        z_statistic = mean_difference / std_error_difference\n",
    "        \n",
    "        # Compute p-value\n",
    "        p_value = norm.cdf(z_statistic)\n",
    "        \n",
    "        p_values[i] = p_value\n",
    "    \n",
    "    # Sort indices based on p-values\n",
    "    return p_values\n",
    "\n",
    "# Example gene expression data for two groups (replace with your actual data)\n",
    "\n",
    "p_values = two_sample_z_test_for_features(gene_expression_data[gene_expression_data['state'] == 0], gene_expression_data[gene_expression_data['state'] == 1])\n",
    "\n",
    "# # Print the p-values\n",
    "print(\"P-values:\", p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007_s_at</td>\n",
       "      <td>0.997118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1053_at</td>\n",
       "      <td>0.857412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117_at</td>\n",
       "      <td>0.401219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121_at</td>\n",
       "      <td>0.445731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255_g_at</td>\n",
       "      <td>0.969285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54671</th>\n",
       "      <td>AFFX-ThrX-M_at</td>\n",
       "      <td>0.870082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54672</th>\n",
       "      <td>AFFX-TrpnX-3_at</td>\n",
       "      <td>0.710107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54673</th>\n",
       "      <td>AFFX-TrpnX-5_at</td>\n",
       "      <td>0.973205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54674</th>\n",
       "      <td>AFFX-TrpnX-M_at</td>\n",
       "      <td>0.181570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54675</th>\n",
       "      <td>state</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54676 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature   P-value\n",
       "0            1007_s_at  0.997118\n",
       "1              1053_at  0.857412\n",
       "2               117_at  0.401219\n",
       "3               121_at  0.445731\n",
       "4            1255_g_at  0.969285\n",
       "...                ...       ...\n",
       "54671   AFFX-ThrX-M_at  0.870082\n",
       "54672  AFFX-TrpnX-3_at  0.710107\n",
       "54673  AFFX-TrpnX-5_at  0.973205\n",
       "54674  AFFX-TrpnX-M_at  0.181570\n",
       "54675            state  0.000000\n",
       "\n",
       "[54676 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df to store feature and p-value\n",
    "z_test_data = pd.DataFrame({'Feature': list(gene_expression_data.columns), 'P-value': p_values})\n",
    "\n",
    "z_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_z_test = z_test_data[z_test_data['P-value'] < 0.01]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1552275_s_at</td>\n",
       "      <td>0.003488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1552295_a_at</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1552299_at</td>\n",
       "      <td>0.005588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1552375_at</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1552411_at</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54444</th>\n",
       "      <td>48808_at</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54571</th>\n",
       "      <td>65133_i_at</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54577</th>\n",
       "      <td>65585_at</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54629</th>\n",
       "      <td>AFFX-HUMGAPDH/M33197_3_at</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54675</th>\n",
       "      <td>state</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1015 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature   P-value\n",
       "24                  1552275_s_at  0.003488\n",
       "38                  1552295_a_at  0.001715\n",
       "40                    1552299_at  0.005588\n",
       "88                    1552375_at  0.001143\n",
       "113                   1552411_at  0.008763\n",
       "...                          ...       ...\n",
       "54444                   48808_at  0.002311\n",
       "54571                 65133_i_at  0.001285\n",
       "54577                   65585_at  0.000960\n",
       "54629  AFFX-HUMGAPDH/M33197_3_at  0.000082\n",
       "54675                      state  0.000000\n",
       "\n",
       "[1015 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_z_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilkoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def wilcoxon_rank_sum_test(data_group1, data_group2):\n",
    "    num_features = data_group1.shape[1]\n",
    "    p_values = np.zeros(num_features)\n",
    "    for i in range(num_features):\n",
    "        feature_group1 = data_group1.iloc[:, i]\n",
    "        feature_group2 = data_group2.iloc[:, i]\n",
    "        u_statistic, p_value = mannwhitneyu(feature_group1, feature_group2)\n",
    "        p_values[i] = p_value\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = wilcoxon_rank_sum_test(gene_expression_data[gene_expression_data['state'] == 0], gene_expression_data[gene_expression_data['state'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007_s_at</td>\n",
       "      <td>1.853688e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1053_at</td>\n",
       "      <td>3.769684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117_at</td>\n",
       "      <td>9.372882e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121_at</td>\n",
       "      <td>9.047548e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255_g_at</td>\n",
       "      <td>9.132303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54671</th>\n",
       "      <td>AFFX-ThrX-M_at</td>\n",
       "      <td>1.221751e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54672</th>\n",
       "      <td>AFFX-TrpnX-3_at</td>\n",
       "      <td>6.916096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54673</th>\n",
       "      <td>AFFX-TrpnX-5_at</td>\n",
       "      <td>2.074898e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54674</th>\n",
       "      <td>AFFX-TrpnX-M_at</td>\n",
       "      <td>3.595208e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54675</th>\n",
       "      <td>state</td>\n",
       "      <td>1.304155e-79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54676 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature      P-values\n",
       "0            1007_s_at  1.853688e-03\n",
       "1              1053_at  3.769684e-01\n",
       "2               117_at  9.372882e-01\n",
       "3               121_at  9.047548e-01\n",
       "4            1255_g_at  9.132303e-04\n",
       "...                ...           ...\n",
       "54671   AFFX-ThrX-M_at  1.221751e-01\n",
       "54672  AFFX-TrpnX-3_at  6.916096e-01\n",
       "54673  AFFX-TrpnX-5_at  2.074898e-01\n",
       "54674  AFFX-TrpnX-M_at  3.595208e-01\n",
       "54675            state  1.304155e-79\n",
       "\n",
       "[54676 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_data = pd.DataFrame({'Feature' : list(gene_expression_data.columns), 'P-values' : p_values})\n",
    "\n",
    "wilcoxon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_wicoxon_test = wilcoxon_data[wilcoxon_data['P-values'] < 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentando intersezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1553691_at\n",
       "1      207981_s_at\n",
       "2      205110_s_at\n",
       "3        243313_at\n",
       "4        227109_at\n",
       "          ...     \n",
       "615    218052_s_at\n",
       "616     1569675_at\n",
       "617    200041_s_at\n",
       "618      200026_at\n",
       "619    207713_s_at\n",
       "Length: 620, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Select values contained in both df derived from statistical test\n",
    "common_values = pd.Series(list(set(relevant_z_test['Feature']).intersection(set(relevant_wicoxon_test['Feature']))))\n",
    "\n",
    "# Print common values\n",
    "common_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = gene_expression_data[common_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1553691_at</th>\n",
       "      <th>207981_s_at</th>\n",
       "      <th>205110_s_at</th>\n",
       "      <th>243313_at</th>\n",
       "      <th>227109_at</th>\n",
       "      <th>226716_at</th>\n",
       "      <th>229013_at</th>\n",
       "      <th>242220_at</th>\n",
       "      <th>238146_at</th>\n",
       "      <th>243529_at</th>\n",
       "      <th>...</th>\n",
       "      <th>203612_at</th>\n",
       "      <th>211358_s_at</th>\n",
       "      <th>201076_at</th>\n",
       "      <th>237829_at</th>\n",
       "      <th>221923_s_at</th>\n",
       "      <th>218052_s_at</th>\n",
       "      <th>1569675_at</th>\n",
       "      <th>200041_s_at</th>\n",
       "      <th>200026_at</th>\n",
       "      <th>207713_s_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM7500908_S001.Cel.gz</th>\n",
       "      <td>1.225292</td>\n",
       "      <td>1.313148</td>\n",
       "      <td>1.359060</td>\n",
       "      <td>1.506253</td>\n",
       "      <td>1.535293</td>\n",
       "      <td>1.489040</td>\n",
       "      <td>1.516727</td>\n",
       "      <td>1.028131</td>\n",
       "      <td>1.169528</td>\n",
       "      <td>1.448122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462536</td>\n",
       "      <td>1.581234</td>\n",
       "      <td>1.644090</td>\n",
       "      <td>0.817706</td>\n",
       "      <td>1.712142</td>\n",
       "      <td>1.671435</td>\n",
       "      <td>1.305611</td>\n",
       "      <td>1.637152</td>\n",
       "      <td>1.881524</td>\n",
       "      <td>1.521668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500909_S002.Cel.gz</th>\n",
       "      <td>1.062832</td>\n",
       "      <td>1.186839</td>\n",
       "      <td>1.280693</td>\n",
       "      <td>1.597401</td>\n",
       "      <td>1.532151</td>\n",
       "      <td>1.522331</td>\n",
       "      <td>1.545113</td>\n",
       "      <td>1.033291</td>\n",
       "      <td>1.098236</td>\n",
       "      <td>1.515536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475042</td>\n",
       "      <td>1.425465</td>\n",
       "      <td>1.591528</td>\n",
       "      <td>0.981414</td>\n",
       "      <td>1.701371</td>\n",
       "      <td>1.636631</td>\n",
       "      <td>1.395837</td>\n",
       "      <td>1.587039</td>\n",
       "      <td>1.836226</td>\n",
       "      <td>1.522117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500910_S003.Cel.gz</th>\n",
       "      <td>1.131377</td>\n",
       "      <td>1.298498</td>\n",
       "      <td>1.403350</td>\n",
       "      <td>1.473587</td>\n",
       "      <td>1.682183</td>\n",
       "      <td>1.519971</td>\n",
       "      <td>1.506545</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>1.093898</td>\n",
       "      <td>1.414270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414203</td>\n",
       "      <td>1.500308</td>\n",
       "      <td>1.689731</td>\n",
       "      <td>0.839616</td>\n",
       "      <td>1.718334</td>\n",
       "      <td>1.702477</td>\n",
       "      <td>1.082388</td>\n",
       "      <td>1.675606</td>\n",
       "      <td>1.903932</td>\n",
       "      <td>1.523278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500911_S004.Cel.gz</th>\n",
       "      <td>1.202369</td>\n",
       "      <td>1.612950</td>\n",
       "      <td>1.279655</td>\n",
       "      <td>1.526723</td>\n",
       "      <td>1.595183</td>\n",
       "      <td>1.511658</td>\n",
       "      <td>1.503475</td>\n",
       "      <td>0.983605</td>\n",
       "      <td>1.095195</td>\n",
       "      <td>1.457116</td>\n",
       "      <td>...</td>\n",
       "      <td>1.495686</td>\n",
       "      <td>1.584171</td>\n",
       "      <td>1.681038</td>\n",
       "      <td>0.841426</td>\n",
       "      <td>1.704953</td>\n",
       "      <td>1.694199</td>\n",
       "      <td>1.045028</td>\n",
       "      <td>1.671271</td>\n",
       "      <td>1.900429</td>\n",
       "      <td>1.556503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7500912_S005.Cel.gz</th>\n",
       "      <td>1.153574</td>\n",
       "      <td>1.157660</td>\n",
       "      <td>1.257012</td>\n",
       "      <td>1.501853</td>\n",
       "      <td>1.547030</td>\n",
       "      <td>1.578844</td>\n",
       "      <td>1.536319</td>\n",
       "      <td>1.058704</td>\n",
       "      <td>1.162363</td>\n",
       "      <td>1.410651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.495737</td>\n",
       "      <td>1.492215</td>\n",
       "      <td>1.710224</td>\n",
       "      <td>0.984399</td>\n",
       "      <td>1.725292</td>\n",
       "      <td>1.656427</td>\n",
       "      <td>1.192759</td>\n",
       "      <td>1.630143</td>\n",
       "      <td>1.886836</td>\n",
       "      <td>1.556072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501261_P035.Cel.gz</th>\n",
       "      <td>1.147816</td>\n",
       "      <td>1.637400</td>\n",
       "      <td>1.278588</td>\n",
       "      <td>1.456428</td>\n",
       "      <td>1.663887</td>\n",
       "      <td>1.458557</td>\n",
       "      <td>1.504388</td>\n",
       "      <td>1.014861</td>\n",
       "      <td>1.197167</td>\n",
       "      <td>1.426761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.486310</td>\n",
       "      <td>1.207048</td>\n",
       "      <td>1.670810</td>\n",
       "      <td>0.791599</td>\n",
       "      <td>1.730239</td>\n",
       "      <td>1.617975</td>\n",
       "      <td>1.015816</td>\n",
       "      <td>1.611504</td>\n",
       "      <td>1.902945</td>\n",
       "      <td>1.532511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501262_P036.Cel.gz</th>\n",
       "      <td>1.192630</td>\n",
       "      <td>1.721684</td>\n",
       "      <td>1.536538</td>\n",
       "      <td>1.440742</td>\n",
       "      <td>1.701499</td>\n",
       "      <td>1.470744</td>\n",
       "      <td>1.625877</td>\n",
       "      <td>1.012833</td>\n",
       "      <td>1.198941</td>\n",
       "      <td>1.475392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.525174</td>\n",
       "      <td>1.433548</td>\n",
       "      <td>1.696604</td>\n",
       "      <td>0.812295</td>\n",
       "      <td>1.777617</td>\n",
       "      <td>1.662767</td>\n",
       "      <td>1.183348</td>\n",
       "      <td>1.649008</td>\n",
       "      <td>1.908255</td>\n",
       "      <td>1.451972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501263_P037.Cel.gz</th>\n",
       "      <td>1.089851</td>\n",
       "      <td>1.708745</td>\n",
       "      <td>1.522660</td>\n",
       "      <td>1.339401</td>\n",
       "      <td>1.653350</td>\n",
       "      <td>1.489439</td>\n",
       "      <td>1.538267</td>\n",
       "      <td>1.007865</td>\n",
       "      <td>1.150353</td>\n",
       "      <td>1.514231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571155</td>\n",
       "      <td>1.359135</td>\n",
       "      <td>1.696991</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>1.803706</td>\n",
       "      <td>1.683033</td>\n",
       "      <td>0.982470</td>\n",
       "      <td>1.658026</td>\n",
       "      <td>1.917754</td>\n",
       "      <td>1.519792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501264_P038.Cel.gz</th>\n",
       "      <td>1.094012</td>\n",
       "      <td>1.743747</td>\n",
       "      <td>1.447948</td>\n",
       "      <td>1.432497</td>\n",
       "      <td>1.695086</td>\n",
       "      <td>1.465050</td>\n",
       "      <td>1.592223</td>\n",
       "      <td>0.996634</td>\n",
       "      <td>1.245597</td>\n",
       "      <td>1.553850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.619992</td>\n",
       "      <td>1.381423</td>\n",
       "      <td>1.691502</td>\n",
       "      <td>0.880074</td>\n",
       "      <td>1.870727</td>\n",
       "      <td>1.707864</td>\n",
       "      <td>1.067455</td>\n",
       "      <td>1.715104</td>\n",
       "      <td>1.928634</td>\n",
       "      <td>1.500414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM7501265_P039.Cel.gz</th>\n",
       "      <td>1.109439</td>\n",
       "      <td>1.174545</td>\n",
       "      <td>1.607680</td>\n",
       "      <td>1.430035</td>\n",
       "      <td>1.601904</td>\n",
       "      <td>1.489287</td>\n",
       "      <td>1.574194</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>1.295679</td>\n",
       "      <td>1.572468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573101</td>\n",
       "      <td>1.322613</td>\n",
       "      <td>1.685806</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>1.792567</td>\n",
       "      <td>1.646196</td>\n",
       "      <td>1.007897</td>\n",
       "      <td>1.708210</td>\n",
       "      <td>1.916920</td>\n",
       "      <td>1.492645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows Ã— 620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        1553691_at  207981_s_at  205110_s_at  243313_at  \\\n",
       "GSM7500908_S001.Cel.gz    1.225292     1.313148     1.359060   1.506253   \n",
       "GSM7500909_S002.Cel.gz    1.062832     1.186839     1.280693   1.597401   \n",
       "GSM7500910_S003.Cel.gz    1.131377     1.298498     1.403350   1.473587   \n",
       "GSM7500911_S004.Cel.gz    1.202369     1.612950     1.279655   1.526723   \n",
       "GSM7500912_S005.Cel.gz    1.153574     1.157660     1.257012   1.501853   \n",
       "...                            ...          ...          ...        ...   \n",
       "GSM7501261_P035.Cel.gz    1.147816     1.637400     1.278588   1.456428   \n",
       "GSM7501262_P036.Cel.gz    1.192630     1.721684     1.536538   1.440742   \n",
       "GSM7501263_P037.Cel.gz    1.089851     1.708745     1.522660   1.339401   \n",
       "GSM7501264_P038.Cel.gz    1.094012     1.743747     1.447948   1.432497   \n",
       "GSM7501265_P039.Cel.gz    1.109439     1.174545     1.607680   1.430035   \n",
       "\n",
       "                        227109_at  226716_at  229013_at  242220_at  238146_at  \\\n",
       "GSM7500908_S001.Cel.gz   1.535293   1.489040   1.516727   1.028131   1.169528   \n",
       "GSM7500909_S002.Cel.gz   1.532151   1.522331   1.545113   1.033291   1.098236   \n",
       "GSM7500910_S003.Cel.gz   1.682183   1.519971   1.506545   0.951276   1.093898   \n",
       "GSM7500911_S004.Cel.gz   1.595183   1.511658   1.503475   0.983605   1.095195   \n",
       "GSM7500912_S005.Cel.gz   1.547030   1.578844   1.536319   1.058704   1.162363   \n",
       "...                           ...        ...        ...        ...        ...   \n",
       "GSM7501261_P035.Cel.gz   1.663887   1.458557   1.504388   1.014861   1.197167   \n",
       "GSM7501262_P036.Cel.gz   1.701499   1.470744   1.625877   1.012833   1.198941   \n",
       "GSM7501263_P037.Cel.gz   1.653350   1.489439   1.538267   1.007865   1.150353   \n",
       "GSM7501264_P038.Cel.gz   1.695086   1.465050   1.592223   0.996634   1.245597   \n",
       "GSM7501265_P039.Cel.gz   1.601904   1.489287   1.574194   0.975727   1.295679   \n",
       "\n",
       "                        243529_at  ...  203612_at  211358_s_at  201076_at  \\\n",
       "GSM7500908_S001.Cel.gz   1.448122  ...   1.462536     1.581234   1.644090   \n",
       "GSM7500909_S002.Cel.gz   1.515536  ...   1.475042     1.425465   1.591528   \n",
       "GSM7500910_S003.Cel.gz   1.414270  ...   1.414203     1.500308   1.689731   \n",
       "GSM7500911_S004.Cel.gz   1.457116  ...   1.495686     1.584171   1.681038   \n",
       "GSM7500912_S005.Cel.gz   1.410651  ...   1.495737     1.492215   1.710224   \n",
       "...                           ...  ...        ...          ...        ...   \n",
       "GSM7501261_P035.Cel.gz   1.426761  ...   1.486310     1.207048   1.670810   \n",
       "GSM7501262_P036.Cel.gz   1.475392  ...   1.525174     1.433548   1.696604   \n",
       "GSM7501263_P037.Cel.gz   1.514231  ...   1.571155     1.359135   1.696991   \n",
       "GSM7501264_P038.Cel.gz   1.553850  ...   1.619992     1.381423   1.691502   \n",
       "GSM7501265_P039.Cel.gz   1.572468  ...   1.573101     1.322613   1.685806   \n",
       "\n",
       "                        237829_at  221923_s_at  218052_s_at  1569675_at  \\\n",
       "GSM7500908_S001.Cel.gz   0.817706     1.712142     1.671435    1.305611   \n",
       "GSM7500909_S002.Cel.gz   0.981414     1.701371     1.636631    1.395837   \n",
       "GSM7500910_S003.Cel.gz   0.839616     1.718334     1.702477    1.082388   \n",
       "GSM7500911_S004.Cel.gz   0.841426     1.704953     1.694199    1.045028   \n",
       "GSM7500912_S005.Cel.gz   0.984399     1.725292     1.656427    1.192759   \n",
       "...                           ...          ...          ...         ...   \n",
       "GSM7501261_P035.Cel.gz   0.791599     1.730239     1.617975    1.015816   \n",
       "GSM7501262_P036.Cel.gz   0.812295     1.777617     1.662767    1.183348   \n",
       "GSM7501263_P037.Cel.gz   0.877750     1.803706     1.683033    0.982470   \n",
       "GSM7501264_P038.Cel.gz   0.880074     1.870727     1.707864    1.067455   \n",
       "GSM7501265_P039.Cel.gz   0.953416     1.792567     1.646196    1.007897   \n",
       "\n",
       "                        200041_s_at  200026_at  207713_s_at  \n",
       "GSM7500908_S001.Cel.gz     1.637152   1.881524     1.521668  \n",
       "GSM7500909_S002.Cel.gz     1.587039   1.836226     1.522117  \n",
       "GSM7500910_S003.Cel.gz     1.675606   1.903932     1.523278  \n",
       "GSM7500911_S004.Cel.gz     1.671271   1.900429     1.556503  \n",
       "GSM7500912_S005.Cel.gz     1.630143   1.886836     1.556072  \n",
       "...                             ...        ...          ...  \n",
       "GSM7501261_P035.Cel.gz     1.611504   1.902945     1.532511  \n",
       "GSM7501262_P036.Cel.gz     1.649008   1.908255     1.451972  \n",
       "GSM7501263_P037.Cel.gz     1.658026   1.917754     1.519792  \n",
       "GSM7501264_P038.Cel.gz     1.715104   1.928634     1.500414  \n",
       "GSM7501265_P039.Cel.gz     1.708210   1.916920     1.492645  \n",
       "\n",
       "[358 rows x 620 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 286\n",
      "Validation set size: 36\n",
      "Test set size: 36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = selected_data.drop('state', axis=1)  # Feature\n",
    "y = selected_data['state']  # Target\n",
    "\n",
    "# Divide df mantaining class distribution\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Validation and test split\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Stampa le dimensioni dei set di dati\n",
    "print(\"Train set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28,  4],\n",
       "       [ 2,  2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = dt_classifier.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "confusion_matrix(y_val, y_val_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8888888888888888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32,  0],\n",
       "       [ 4,  0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize Linear SVM Classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = svm_classifier.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "confusion_matrix(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(400,300,160,24,), activation='logistic', solver='adam', random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = mlp_classifier.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32,  0],\n",
       "       [ 4,  0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute confusion matrix for validation set\n",
    "confusion_matrix(y_val, y_val_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with zscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = gene_expression_data[relevant_z_test['Feature']].drop('state', axis=1)  # Feature\n",
    "y = gene_expression_data['state']  # Target\n",
    "\n",
    "# Divide df mantaining class distribution\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Validation and test split\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28,  4],\n",
       "       [ 2,  2]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = dt_classifier.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "confusion_matrix(y_val, y_val_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(400,300,160,24,), activation='logistic', solver='adam', random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = mlp_classifier.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32,  0],\n",
       "       [ 4,  0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non c'Ã¨ speranza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=300)  # You can adjust n_estimators and other parameters as needed\n",
    "\n",
    "# Train the classifier on the balanced training data\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation_rf = rf_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining K-Fold Cross-Validation\n",
    "n_splits = 6\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Computing class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Getting weights dictionary\n",
    "class_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8958333134651184\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        43\n",
      "           1       0.50      0.40      0.44         5\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.72      0.68      0.69        48\n",
      "weighted avg       0.89      0.90      0.89        48\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  2]\n",
      " [ 3  2]]\n",
      "ROC AUC Score: 0.6767441860465115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8958333134651184\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        43\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.45      0.50      0.47        48\n",
      "weighted avg       0.80      0.90      0.85        48\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43  0]\n",
      " [ 5  0]]\n",
      "ROC AUC Score: 0.2558139534883721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8958333134651184\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        43\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.45      0.50      0.47        48\n",
      "weighted avg       0.80      0.90      0.85        48\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43  0]\n",
      " [ 5  0]]\n",
      "ROC AUC Score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8541666865348816\n",
      "2/2 [==============================] - 0s 961us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        42\n",
      "           1       0.40      0.33      0.36         6\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.65      0.63      0.64        48\n",
      "weighted avg       0.84      0.85      0.85        48\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 4  2]]\n",
      "ROC AUC Score: 0.6309523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7021276354789734\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81        42\n",
      "           1       0.20      0.60      0.30         5\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.57      0.66      0.56        47\n",
      "weighted avg       0.86      0.70      0.76        47\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30 12]\n",
      " [ 2  3]]\n",
      "ROC AUC Score: 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/ntrkgb291jn46fk1gj1cw5wr0000gn/T/ipykernel_25507/664425235.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8723404407501221\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        42\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.87        47\n",
      "   macro avg       0.45      0.49      0.47        47\n",
      "weighted avg       0.80      0.87      0.83        47\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  1]\n",
      " [ 5  0]]\n",
      "ROC AUC Score: 0.4880952380952381\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    return model\n",
    "\n",
    "# Training and evaluation\n",
    "for train_index, test_index in skf.split(X_train_scaled, y_train):\n",
    "    # Splitting data\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(input_dim=X_train_fold.shape[1])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = Adam(),\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, y_train_fold,\n",
    "                        validation_data=(X_val_fold, y_val_fold),\n",
    "                        epochs=500, batch_size=10, verbose=0, class_weight=class_weight_dict)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    print(f'Validation Accuracy: {scores[1]}')\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_val_fold, y_pred > 0.5))  # Threshold can be adjusted\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred > 0.5)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # ROC AUC Score\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_pred)\n",
    "    print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_val_fold, y_pred)\n",
    "    # Plot ROC curve\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_val_fold, y_pred)\n",
    "    # Plot Precision-Recall curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
